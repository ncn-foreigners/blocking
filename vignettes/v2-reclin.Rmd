---
title: "Blocking records for record linkage"
author: "Maciej BerÄ™sewicz"
execute:
  warning: false
  message: false
lang: en
output: 
    html_vignette:
        df_print: kable
        toc: true
        number_sections: true
        fig_width: 6
        fig_height: 4
vignette: >
  %\VignetteIndexEntry{Blocking records for record linkage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Setup

Read required packages

```{r setup}
library(blocking)
library(reclin2)
library(data.table)
```

# Data

Read the example data from the tutorial on [the `reclin` package on the URos 2021 Conference](https://github.com/djvanderlaan/tutorial-reclin-uros2021). The data sets are from ESSnet on Data Integration as stated in the repository:

```
These totally fictional data sets are supposed to have captured details of
persons up to the date 31 December 2011.  Any years of birth captured as 2012
are therefore in error.  Note that in the fictional Census data set, dates of
birth between 27 March 2011 and 31 December 2011 are not necessarily in error.

Census: A fictional data set to represent some observations from a
        decennial Census
CIS: Fictional observations from Customer Information System, which is
        combined administrative data from the tax and benefit systems

In the dataset census all records contain a person_id. For some of the records
in cis the person_id is also available. This information can be used to
evaluate the linkage (assuming these records from the cis are representable 
all records in the cis). 
```

```{r}
census <- read.csv("https://raw.githubusercontent.com/djvanderlaan/tutorial-reclin-uros2021/main/data/census.csv")
cis <- read.csv("https://raw.githubusercontent.com/djvanderlaan/tutorial-reclin-uros2021/main/data/cis.csv")
setDT(census)
setDT(cis)
```

+ `census` object has `r nrow(census)` rows and `r ncol(census)`,
+ `cis` object has `r nrow(census)` rows and `r ncol(census)`.

Census data

```{r}
head(census)
```
CIS data

```{r}
head(cis)
```

We need to create new columns that concatanates variables from `pername1` to `enumpc`. In the first step we replace `NA`s with `''`. 

```{r}
census[is.na(dob_day), dob_day := ""]
census[is.na(dob_mon), dob_mon := ""]
census[is.na(dob_year), dob_year := ""]
cis[is.na(dob_day), dob_day := ""]
cis[is.na(dob_mon), dob_mon := ""]
cis[is.na(dob_year), dob_year := ""]

census[, txt:=paste0(pername1, pername2, sex, dob_day, dob_mon, dob_year, enumcap, enumpc)]
cis[, txt:=paste0(pername1, pername2, sex, dob_day, dob_mon, dob_year, enumcap, enumpc)]
```


# Linking datasets

## Using basic functionalities of `blocking` package

The goal of this exercise is to link units from the CIS dataset to the CENSUS dataset. 

```{r}
result1 <- blocking(x = census$txt, y = cis$txt, verbose = 1, seed = 2024)
```

Distribution of distances for pairs

```{r}
hist(result1$result$dist, main = "Distribution of distances between pairs", xlab = "Distances")
```

Example pairs

```{r}
head(result1$result, n= 10)
```

Let's look at the first pair. Clearly there is a typo on the `pername1` but all other variables are the same so it seems that this is a match.

```{r}
census[1, ]
cis[8152, ]
```

Now, let's look at the 7th pair with the largest distance from the first 10 rows. This seems to be a non-match because only `pername2` and `sex` are the same.

```{r}
census[8, ]
cis[3901, ]
```


## Assessing the quality

For some records we have information on the correct linkage. We can use this information to assess our approach but note that information on assessing the quality is described in detail in the other vignette. 

```{r}
matches <- merge(x = census[, .(x=1:.N, person_id)],
                 y = cis[, .(y = 1:.N, person_id)],
                 by = "person_id")
matches[, block:=1:.N]
head(matches)
```
So in our example we have `r nrow(matches)` pairs.

```{r}
result2 <- blocking(x = census$txt, y = cis$txt, verbose = 1, seed = 2024,
                    true_blocks = matches[, .(x, y, block)], n_threads = 4)
```

Let's see how our approach handled this problem.

```{r}
result2
```

It seems that default parameters of the NND method result in FNR of 16% which is quite large. Let's compare to HNSW algorithm.

```{r}
result3 <- blocking(x = census$txt, y = cis$txt, seed = 2024, verbose = 1, 
                    true_blocks = matches[, .(x, y, block)], n_threads = 4, 
                    ann = "hnsw")
```

```{r}
result3
```

It seems that the HNSW algorithm performed better with 0.62% FNR. This however comes with cost, in particupar computational cost:

1. the HNSW does not handle sparse matrices so sparse matrix of tokens is converted to dense.
2. HNSW algorithm is slower than NND. 

Computational times are: 16 seconds for NND and about 60 HNSW (on M2 MacBook AIR).


